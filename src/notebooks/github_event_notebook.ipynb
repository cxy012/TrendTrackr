{"cells":[{"cell_type":"markdown","source":["# GitHub Data Analysis using Microsoft Fabric Notebook\n","\n","## Section 1: Setup and Data Loading"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ff715e12-5a89-4ddb-8db0-45467bda022f"},{"cell_type":"code","source":["# Import necessary libraries\n","from pyspark.sql import SparkSession\n","\n","# Create Spark Session\n","spark = SparkSession.builder.getOrCreate()\n","\n","# Define Azure Data Lake Storage paths\n","URL = 'abfss://github_event@onelake.dfs.fabric.microsoft.com/github_event_lakehouse.Lakehouse/Tables/'\n","\n","# Format URLs to access each table's data in the Data Lake Storage\n","adl_url_events = f\"{URL}/public_events/\"\n","adl_url_push_events = f\"{URL}/public_push_events/\"\n","adl_url_commits = f\"{URL}/public_commits/\"\n","adl_url_pull_request_events = f\"{URL}/public_pull_request_events/\"\n","adl_url_trending = f\"{URL}/public_trending/\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"828619f3-a2c7-4655-aac8-f34f738c6020"},{"cell_type":"markdown","source":["## Section 2: Load Data from Azure Data Lake Storage"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b24f08f6-9535-4653-bde6-fd82597bb554"},{"cell_type":"code","source":["# Load data from the specified folders in the Azure Data Lake Storage\n","# The data is stored in Delta format for efficient querying\n","events_df = spark.read.format(\"Delta\").load(adl_url_events)\n","push_events_df = spark.read.format(\"Delta\").load(adl_url_push_events)\n","commits_df = spark.read.format(\"Delta\").load(adl_url_commits)\n","pull_request_events_df = spark.read.format(\"Delta\").load(adl_url_pull_request_events)\n","trending_df = spark.read.format(\"Delta\").load(adl_url_trending)\n","\n","# Create temporary views for SQL queries\n","events_df.createOrReplaceTempView(\"events\")\n","push_events_df.createOrReplaceTempView(\"push_events\")\n","pull_request_events_df.createOrReplaceTempView(\"pull_requests\")\n","trending_df.createOrReplaceTempView(\"trending\")\n","commits_df.createOrReplaceTempView(\"commits\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ac83e6aa-9f17-47fc-b4d1-a1fbc6fbcda8"},{"cell_type":"markdown","source":["## Section 3: Data Analysis"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5cdab8e1-cb23-4be2-b9b5-b0410e336cef"},{"cell_type":"markdown","source":["###  General GitHub Events Analysis"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c8127552-809d-4c04-874d-301aa6acc481"},{"cell_type":"code","source":["# Count the number of events by date to understand general activity trends\n","activity_df = spark.sql(\"\"\"\n","    SELECT date(created_at) as event_date, COUNT(*) as event_count\n","    FROM events\n","    GROUP BY event_date\n","    ORDER BY event_date\n","\"\"\")\n","\n","# Save the analysis result as a Delta table for further use\n","activity_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"activity_count\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8f98e9d5-64fa-440a-bcc5-f5b2e13d23f6"},{"cell_type":"markdown","source":["### Contributor Activity Analysis"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"eb67ef9e-4df3-436e-b799-fc08336c6a3b"},{"cell_type":"code","source":["# Analyze the activity of contributors by counting the number of events each has triggered\n","contributor_activity_df = spark.sql(\"\"\"\n","    SELECT actor_login, COUNT(*) as event_count\n","    FROM events\n","    GROUP BY actor_login\n","    ORDER BY event_count DESC\n","\"\"\")\n","\n","# Save the analysis result as a Delta table for further use\n","contributor_activity_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"contributor_activity\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6d5cedd0-5e17-4a6f-bd50-f5d076d2ad0a"},{"cell_type":"markdown","source":["### Repository Activity Trend Analysis"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4e3871f9-a8da-4ff8-a02d-6e846c99ea67"},{"cell_type":"code","source":["# Count the number of push and pull request events per repository to determine the most active ones\n","repo_activity_df = spark.sql(\"\"\"\n","    SELECT events.repo_name,\n","           COUNT(DISTINCT push_events.id) AS push_count,\n","           COUNT(DISTINCT pull_requests.id) AS pull_request_count\n","    FROM events\n","    LEFT JOIN push_events ON events.id = push_events.event_id\n","    LEFT JOIN pull_requests ON events.id = pull_requests.event_id\n","    GROUP BY events.repo_name\n","    ORDER BY push_count DESC, pull_request_count DESC\n","\"\"\")\n","\n","# Save the repository activity analysis result for further use\n","repo_activity_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"repo_activity\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"49a0cb27-41e6-49e3-8833-386b68ebe743"},{"cell_type":"markdown","source":["### Programming Language Popularity Analysis"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cda22970-3e20-4293-991a-3730b946877b"},{"cell_type":"code","source":["# Analyze the popularity of programming languages by counting the number of repositories and summing up the stars\n","language_popularity_df = spark.sql(\"\"\"\n","    SELECT language, COUNT(*) as repo_count, SUM(stars) as total_stars\n","    FROM trending\n","    WHERE language IS NOT NULL\n","    GROUP BY language\n","    ORDER BY total_stars DESC\n","\"\"\")\n","\n","# Save the analysis result as a Delta table for further use\n","language_popularity_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"language_popularity\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4a5730f2-2aa0-43af-9f21-77ece6b0c6d1"},{"cell_type":"markdown","source":["### Commit Analysis by Author"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c1f197cf-3017-4d85-bfdc-93c033a3fbe5"},{"cell_type":"code","source":["# Count the number of commits made by each author to understand the most active contributors\n","commits_by_author_df = spark.sql(\"\"\"\n","    SELECT author_name, COUNT(*) as commit_count\n","    FROM commits\n","    GROUP BY author_name\n","    ORDER BY commit_count DESC\n","\"\"\")\n","\n","# Save the commit analysis result by author for further use\n","commits_by_author_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"commits_by_author\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f073ef10-0e52-4945-b50a-aa1a707561ee"},{"cell_type":"markdown","source":["### Repository Popularity Analysis"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5e9ba629-5c11-4937-9621-bb68f03cad71"},{"cell_type":"code","source":["# Analyze repository popularity based on the number of stars they received\n","repo_popularity_df = spark.sql(\"\"\"\n","    SELECT repo_name, COUNT(*) as repo_count\n","    FROM trending\n","    GROUP BY repo_name\n","    ORDER BY repo_count DESC\n","\"\"\")\n","# Save the repository popularity analysis result for further use\n","repo_popularity_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"repo_popularity\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dec667c5-e2a5-4205-98dd-7182452d7918"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}