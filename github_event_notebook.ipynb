{"cells":[{"cell_type":"code","source":["URL = 'abfss://github_event@onelake.dfs.fabric.microsoft.com/github_event_lakehouse.Lakehouse/Tables/'\n","\n","# Format URLs to access each table's data in the Data Lake Storage \n","adl_url_events = f\"{URL}/public_events/\"\n","adl_url_push_events = f\"{URL}/public_push_events/\"\n","adl_url_commits = f\"{URL}/public_commits/\"\n","adl_url_pull_request_events = f\"{URL}/public_pull_request_events/\"\n","adl_url_trending = f\"{URL}/public_trending/\"\n","\n","# Load data from the specified folders in the Azure Data Lake Storage\n","events_df = spark.read.format(\"Delta\").load(adl_url_events)\n","push_events_df = spark.read.format(\"Delta\").load(adl_url_push_events)\n","commits_df = spark.read.format(\"Delta\").load(adl_url_commits)\n","pull_request_events_df = spark.read.format(\"Delta\").load(adl_url_pull_request_events)\n","trending_df = spark.read.format(\"Delta\").load(adl_url_trending)\n","\n","events_df.createOrReplaceTempView(\"events\")\n","push_events_df.createOrReplaceTempView(\"push_events\")\n","pull_request_events_df.createOrReplaceTempView(\"pull_requests\")\n","trending_df.createOrReplaceTempView(\"trending\")\n","commits_df.createOrReplaceTempView(\"commits\")\n","\n","activity_df = spark.sql(\"\"\"\n","    SELECT date(created_at) as event_date, COUNT(*) as event_count\n","    FROM events\n","    GROUP BY event_date\n","    ORDER BY event_date\n","\"\"\")\n","\n","contributor_activity_df = spark.sql(\"\"\"\n","    SELECT actor_login, COUNT(*) as event_count\n","    FROM events\n","    GROUP BY actor_login\n","    ORDER BY event_count DESC\n","\"\"\")\n","\n","repo_activity_df = spark.sql(\"\"\"\n","    SELECT events.repo_name, \n","           COUNT(DISTINCT push_events.id) AS push_count,\n","           COUNT(DISTINCT pull_requests.id) AS pull_request_count\n","    FROM events\n","    LEFT JOIN push_events ON events.id = push_events.event_id\n","    LEFT JOIN pull_requests ON events.id = pull_requests.event_id\n","    GROUP BY events.repo_name\n","    ORDER BY push_count DESC, pull_request_count DESC\n","\"\"\")\n","\n","language_popularity_df = spark.sql(\"\"\"\n","    SELECT language, COUNT(*) as repo_count, SUM(stars) as total_stars\n","    FROM trending\n","    WHERE language IS NOT NULL\n","    GROUP BY language\n","    ORDER BY total_stars DESC\n","\"\"\")\n","\n","repo_popularity_df = spark.sql(\"\"\"\n","    SELECT repo_name, COUNT(*) as repo_count\n","    FROM trending\n","    GROUP BY repo_name\n","    ORDER BY repo_count DESC\n","\"\"\")\n","\n","commits_by_author_df = spark.sql(\"\"\"\n","    SELECT author_name, COUNT(*) as commit_count\n","    FROM commits\n","    GROUP BY author_name\n","    ORDER BY commit_count DESC\n","\"\"\")\n","\n","activity_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"activity_count\")\n","contributor_activity_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"contributor_activity\")\n","repo_activity_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"repo_activity\")\n","language_popularity_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"language_popularity\")\n","commits_by_author_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"commits_by_author\")\n","repo_popularity_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"repo_popularity\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":null,"statement_ids":null,"state":"waiting","livy_statement_state":null,"session_id":null,"normalized_state":"waiting","queued_time":"2024-11-04T00:58:50.416942Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"c71dc2c3-a16d-461a-b85a-c1b3aaac6a3c"},"text/plain":"StatementMeta(, , , Waiting, , Waiting)"},"metadata":{}}],"execution_count":6,"metadata":{"editable":true,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}},"run_control":{"frozen":false},"advisor":{"adviceMetadata":"{\"artifactId\":\"2b58067a-4e53-4f54-bb75-cc71a0f896fb\",\"activityId\":\"ab9a93f5-db76-43ea-b639-0f2ff651613e\",\"applicationId\":\"application_1730681062310_0001\",\"jobGroupId\":\"4\",\"advices\":{\"warn\":1}}"}},"id":"fc94b6f1-1765-40a4-a5f1-e793d2b995b8"},{"cell_type":"code","source":[],"outputs":[],"execution_count":5,"metadata":{"editable":true,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}},"run_control":{"frozen":false}},"id":"eff08a99-efd7-4625-adc7-df04b408bcfe"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"10ffae9b-fe92-4c6d-99a5-a51dfff7f355","default_lakehouse_name":"github_event_lakehouse","default_lakehouse_workspace_id":"3e2f0f76-7c4b-4abe-8d2f-fa62a22008ca"}}},"nbformat":4,"nbformat_minor":5}